{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA1V/uk14vZPnBUL4aP2+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnaen/ai-dev-toolbox/blob/main/python-tools/transformers/day_2_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [**Tokenizer**](https://huggingface.co/docs/transformers/en/fast_tokenizers)"
      ],
      "metadata": {
        "id": "-hlkpJQwQBlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It does\n",
        "\n",
        "- Add special token (e.g. [CLS], [SEP]).\n",
        "- Convert word to tokens.\n",
        "- convert token to ids using vocab.\n",
        "\n",
        "\n",
        "e.g\n",
        "----\n",
        "\n",
        "text = \"i love you !\"\n",
        "\n",
        "add special tokens = \"[CLS] i love you [SEP]\"\n",
        "\n",
        "covert word to tokens = [\"i\", \"love\", \"you\", \"!\"]\n",
        "\n",
        "covert tokens to ids using vocab = [232, 1012, 434, 5422]"
      ],
      "metadata": {
        "id": "u1NZLFpYMY5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In transformers\n",
        "\n",
        "- There is 2 kind of tokenizers, `fast` and `slow`\n",
        "- `fast` : uses rust based function\n",
        "- `slow` : uses python based function"
      ],
      "metadata": {
        "id": "p9amj8XzQ_S9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "6TrQ9WuSSzW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqePXARAP4IJ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1: str = \"i asked this, is anyone replayed ?\"\n",
        "text2: str = \"why did you do that !\""
      ],
      "metadata": {
        "id": "92gos_gzR_Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")"
      ],
      "metadata": {
        "id": "A8bH7vSOCrNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(text1)   # it return token_id and attention_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68Ed4AQrCuVg",
        "outputId": "bb7e3333-097e-4eaf-e5a9-c948e13fad45"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [1, 474, 4433, 445, 29892, 338, 5019, 337, 1456, 287, 1577], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(text1)   # this only return the tokens"
      ],
      "metadata": {
        "id": "1nawzL3nC0qO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a967570f-8aaf-46b3-cef1-c16f0be73d69"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁i', '▁asked', '▁this', ',', '▁is', '▁anyone', '▁re', 'play', 'ed', '▁?']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = tokenizer.encode(text1)   # this only returns the ids (tokens coverted to ids using vocab)\n",
        "token_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRSrVDlMSMXS",
        "outputId": "a7317972-7673-4985-cc6f-4133a0a441f9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 474, 4433, 445, 29892, 338, 5019, 337, 1456, 287, 1577]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(token_ids)    # decode encoded tokends ids back to tokens (use during model inference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rpeUkf5PSfhX",
        "outputId": "366ed60c-e552-435e-931b-b7e1d1ab2d73"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> i asked this, is anyone replayed ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch encode (encode a document)\n",
        "tokens_ids = tokenizer.encode([text1, text2])\n",
        "tokens_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30543QgmUFRI",
        "outputId": "ad18bfa1-bc36-4970-f0d7-6b7fa58bbc18"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 474,\n",
              " 4433,\n",
              " 445,\n",
              " 29892,\n",
              " 338,\n",
              " 5019,\n",
              " 337,\n",
              " 1456,\n",
              " 287,\n",
              " 1577,\n",
              " 1,\n",
              " 2020,\n",
              " 1258,\n",
              " 366,\n",
              " 437,\n",
              " 393,\n",
              " 1738]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokens_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eUCB_vcgTS6U",
        "outputId": "aee5e4f9-cfe6-4bba-b3de-bb10afb8414f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> i asked this, is anyone replayed ?<s> why did you do that !'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There is 4 type of tokenizers that depends on model architecture.\n",
        "- Use the `AutoTokenizer` when possible.\n",
        "- Use `fast toknizers`, it use by default when its avilable.\n",
        "- All tokenizer models have methods such as\n",
        "    - `encode()`   : return only the token_ids\n",
        "    - `tokenize()` : return only tokens\n",
        "    - `decode()`   : it decode back the token_ids to human readable words\n",
        "    - `__call__()` : it return tokens_ids and attenttion_mask"
      ],
      "metadata": {
        "id": "3jQN7OwCYcJa"
      }
    }
  ]
}